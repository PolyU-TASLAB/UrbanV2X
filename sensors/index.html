<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>The UrbanV2X Datasets | Sensors </title>
    <meta name="author" content="The UrbanV2X Datasets " />
    <meta name="description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    <meta name="keywords" content="Event-based Vision, Multi-sensor, SLAM, Autonomous Driving" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="The UrbanV2X Datasets  " />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The UrbanV2X Datasets   | Sensors" />
    <meta property="og:url" content="http://localhost:4000/UrbanV2X/sensors" />
    <meta property="og:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Sensors" />
    <meta name="twitter:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "The UrbanV2X Datasets  "
        },
        "url": "http://localhost:4000/UrbanV2X/",
        "@type": "WebSite",
        "description": "An Event-Centric Multisensory Driving Dataset for SLAM.
",
        "headline": "Sensors",
        "sameAs": ["https://github.com/arclab-hku/Event_based_VO-VIO-SLAM", "https://arclab.hku.hk/"],
        "name": "The UrbanV2X Datasets  ",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Barriecito&family=Poppins:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/PASTIE.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->

    <link rel="shortcut icon" href="https://polyu-taslab.github.io/UrbanV2X/assets/img/icon.png"/>
    
    <link rel="stylesheet" href="https://polyu-taslab.github.io/UrbanV2X/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/UrbanV2X/sensors">
    <link rel="stylesheet" href="https://polyu-taslab.github.io/UrbanV2X/assets/css/fonts.css">
    <link rel="stylesheet" href="/UrbanV2X/assets/css/fonts.css">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="http://polyu-taslab.github.io/UrbanV2X/"><span class="font-weight: 600">UrbanV2X Dataset</span>   </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- Home -->
              <li class="nav-item">
                <a class="nav-link" href="/UrbanV2X/">Home</a>
              </li>

              <!-- Other pages -->
                <li class="nav-item active">
                  <a class="nav-link" href="/UrbanV2X/sensors/">Sensors<span class="sr-only">(current)</span></a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/UrbanV2X/calibration/">Calibration</a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/UrbanV2X/download/">Download</a>
                </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>
<!-- 以上为include -->

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Sensors</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p><br></p>

          <!-- <figure style="text-align: center;">
             <img style = "width: 90%" src="https://polyu-taslab.github.io/UrbanV2X/assets/img/sensors.JPG" alt="Image description">
          </figure> -->

          <figure style="text-align: center;">
            <img style = "width: 70%" src="https://polyu-taslab.github.io/UrbanV2X/assets/img/sensor_platform.png" alt="Image description">
            <figcaption id="overview">Fig. 1. An overview of the sensor setup</figcaption>
          </figure>

<p><br></p>

<p style="text-align: justify;">
  The data collection platform is shown in <a href="#overview">Fig. 1.</a>. Our sensor suite consists of a multi-camera setup (event camera, industrial camera, 
  and infrared camera) equipped with three LiDARs, onboard IMU, two GNSS receivers, and GNSS-RTK/INS systems.
  The specific specifications of each sensor are presented in <a href="#Sensors specifications">Table. 1.</a> .
  An Intel NUC (i7-1260P, 32GB RAM) and an industrial computer (i7-10610U, 32GB RAM) are used to run sensor drivers, and record data into ROS bags on the Ubuntu system.
<br>
</p>

<h4>Visual sensors</h4>
<p style="text-align: justify;">
  Seven Hikvision MV-CS050-10GC PRO industrial cameras equipped with VM0428MP12 4mm industrial lenses are used, each with a resolution of 2200&times;1740, capturing RGB images at 10 Hz in fixed exposure mode. Among them, two are forward-facing stereo industrial cameras, while the other five cameras are installed at an angle of 60° between each other to form a 360° surround image capture setup. Each camera has a horizontal FOV of approximately 80.18°, with an overlap angle of around 20° between adjacent cameras. Image synchronization and triggering are achieved through the GigE Vision protocol, ensuring a frame trigger error of 0.005s for each image set.
<br>
</p>
<h4>4D Radar</h4>
<p style="text-align: justify;">
  A 4D radar is mounted at the front of the sensor kit, capable of real-time measurement of the position, velocity, and distance of objects ahead, while generating 3D point cloud data fused with velocity information. It features a horizontal field of view of 150° and operates at a collection frequency of 13 Hz.
  <br>
</p>
<h4>Mechanical LiDAR</h4>
<p style="text-align: justify;">
  We configure two mechanical LiDARs including one slanted LiDAR to collect accurate point clouds of surrounding environments.
  Velodyne HDL-32E is positioned on the top of the vehicle to capture the surroundings horizontally.
  The slanted LiDARs, Hesai XT-32, are mounted on the center front part of vehicle.This configuration facilitates the thorough recording of architectural particulars relevant to high-rising buildings in urbanized 
  areas and all LiDAR data are collected at 10 Hz.
<br>
</p>

<h4>Onboard IMU and GNSS-RTK/INS suite</h4>
<p style="text-align: justify;">
  An onboard Xsens-MTI-30 IMU is employed to collect the raw acceleration and angular velocity at 400 Hz.
  The accurate ground-truth of localization is furnished by a centimeter-level GNSS(GPS, GLONASS, and BeiDou)-RTK/INS(fiber-optic gyroscope) navigation system.
<br>
</p>

<p style="text-align: justify;">
The details of full sensors setup can be found below:
<br>
</p>


<div style="text-align: center;">
<table style="display: inline-block;">
  <tablecaption id="Sensors specifications"></tablecaption>
  <tr><td>Sensor Type</td><td>Description</td></tr>
  <tr>
  <td>Hikvision MV-CS050-10GC PRO  &times; 7</td>
  <td>
  <ul>
  <li>2220 &times;1740 pixels at 10 fps</li>
  <li>H-FOV: 80.18&deg;, V-FOV: 73.77&deg;.</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>Roadside Infrastracture</td>
  <td>
  <ul>
  <li>GNSS U-Blox F9P, 1Hz</li>
  <li>Nooploop P-B, 50 Hz</li>
  <li>Innovusion Jaguar, LiDAR, 300 lines</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>Hesai XT-32</td>
  <td>
  <ul>
  <li>H-FOV:360°, V-FOV:+15° ~ -16°.</li>
  <li>32 channel</li>
  <li>10Hz</li>
  <li>125m range</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>Velodyne VLP-32E</td>
  <td>
  <ul>
  <li>H-FOV:360°, V-FOV:-30.67° ~ 10.67°.</li>
  <li>32 channel</li>
  <li>10Hz</li>
  <li>100m range</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>GPAL-Ares-R7861 Radar</td>
  <td>
  <ul>
  <li>H-FOV:150°, V-FOV:30.</li>
  <li>Front-View</li>
  <li>13Hz</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>Xsens Mti-30 IMU</td>
  <td>
  <ul>
  <li>400 Hz</li>
  <li>accelerometer in-run bias instability 15 &mu;g </li>
  <li>gyroscope in-run bias instability 18&deg;/h</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>U-BLOX ZED-F9P</td>
  <td>
  <ul>
  <li>Automobile Level</li>
  <li>1Hz, GPS Time</li>
  </ul>
  </td>
  </tr>
  <tr>
  <td>U-BLOX EVK-M8T</td>
  <td>
  <ul>
  <li>Automobile Level</li>
  <li>1Hz, GPS Time</li>
  </ul>
  </td>
  </tr>
  <td>NovAtel SPAN-CPT</td>
  <td>
  <ul>
  <li>Geodetic Level</li>
  <li>1 Hz, GPS Time</li>
  <li>Position accuracy 5cm</li>
  </ul>
  </td>
  </tr>
  </table>

</div>

  <p><br></p>

<!-- <ul>
  <li>2x <a href="https://www.prophesee.ai/buy-event-based-products/" target="_blank" rel="noopener noreferrer">Prophesee Gen3 CD</a> with <a href="https://lenses.kowa-usa.com/jcm-series/410-lm5jc1m.html" target="_blank" rel="noopener noreferrer">Kowa LM5JCM</a>
</li>
  <li>2x <a href="https://www.flir.com/products/grasshopper3-usb3/?model=GS3-U3-51S5C-C" target="_blank" rel="noopener noreferrer">FLIR Grasshopper3</a> with <a href="https://lenses.kowa-usa.com/jc-series/479-lm6jc.html" target="_blank" rel="noopener noreferrer">Kowa LM6JC</a>
</li>
  <li><a href="https://azure.microsoft.com/en-us/services/kinect-dk/" target="_blank" rel="noopener noreferrer">Azure Kinect</a></li>
  <li><a href="https://ouster.com/products/scanning-lidar/os0-sensor/" target="_blank" rel="noopener noreferrer">Ouster OS0-128</a></li>
  <li><a href="https://www.xsens.com/products/mti-10-series" target="_blank" rel="noopener noreferrer">XSens MTi-30 AHRS</a></li>
  <li><a href="https://optitrack.com/" target="_blank" rel="noopener noreferrer">OptiTrack Motion Capture (MoCap) System</a></li>
  <li><a href="https://www.faro.com/en/Products/Hardware/Focus-Laser-Scanners" target="_blank" rel="noopener noreferrer">FARO Focus Laser Scanner</a></li>
</ul> -->

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="nofixed-bottom">
      <div class="container mt-0" style="width:100%;text-align:center;">
        © 2025 Tas Lab, The University of HongKong. All rights reserved.
      </div>
    </footer> 

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/vector/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/vector/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/vector/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

