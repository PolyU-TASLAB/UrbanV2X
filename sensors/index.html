<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>The UrbanV2X Datasets | Sensors </title>
    <meta name="author" content="The UrbanV2X Datasets " />
    <meta name="description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    <meta name="keywords" content="Event-based Vision, Multi-sensor, SLAM, Autonomous Driving" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="The UrbanV2X Datasets  " />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The UrbanV2X Datasets   | Sensors" />
    <meta property="og:url" content="http://localhost:4000/UrbanV2X/sensors" />
    <meta property="og:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Sensors" />
    <meta name="twitter:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "The UrbanV2X Datasets  "
        },
        "url": "http://localhost:4000/UrbanV2X/",
        "@type": "WebSite",
        "description": "An Event-Centric Multisensory Driving Dataset for SLAM.
",
        "headline": "Sensors",
        "sameAs": ["https://github.com/arclab-hku/Event_based_VO-VIO-SLAM", "https://arclab.hku.hk/"],
        "name": "The UrbanV2X Datasets  ",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Barriecito&family=Poppins:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/PASTIE.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->

    <link rel="shortcut icon" href="https://polyu-taslab.github.io/UrbanV2X/assets/img/icon.png"/>
    
    <link rel="stylesheet" href="https://polyu-taslab.github.io/UrbanV2X/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/UrbanV2X/sensors">
    <link rel="stylesheet" href="https://polyu-taslab.github.io/UrbanV2X/assets/css/fonts.css">
    <link rel="stylesheet" href="/UrbanV2X/assets/css/fonts.css">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="http://polyu-taslab.github.io/UrbanV2X/"><span class="font-weight: 600">UrbanV2X Dataset</span>   </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- Home -->
              <li class="nav-item">
                <a class="nav-link" href="/UrbanV2X/index.html">Home</a>
              </li>

              <!-- Other pages -->
                <li class="nav-item active">
                  <a class="nav-link" href="/UrbanV2X/sensors/index.html">Sensors<span class="sr-only">(current)</span></a>
                </li>
                <!-- <li class="nav-item ">
                  <a class="nav-link" href="/UrbanV2X/calibration/">Calibration</a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/UrbanV2X/download/">Download</a>
                </li> -->
            </ul>
          </div>
        </div>
      </nav>
    </header>
<!-- 以上为include -->

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Sensors</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p><br></p>

          <figure style="text-align: center; position: relative; width: 90%; margin: 0 auto;">
            <!-- 加载标记 -->
            <div id="loading" style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);">
              <span>Sensor-kit Overview Loading...</span> <!-- 或使用一个加载动画 -->
            </div>
          
            <!-- 图片 -->
            <img id="sensorImage" style="width: 100%; display: none;" src="/UrbanV2X/assets/gif/onboard_platform_speedX4.gif" alt="Image description">
          </figure>
          
          <script>
            // 获取图片和加载标记
            const image = document.getElementById('sensorImage');
            const loading = document.getElementById('loading');
          
            // 图片加载成功时
            image.onload = () => {
              loading.style.display = 'none'; // 隐藏加载标记
              image.style.display = 'block'; // 显示图片
            };
          
            // 图片加载失败时（可选）
            image.onerror = () => {
              loading.innerHTML = 'Failed to load image'; // 显示错误信息
            };
          </script>

          

<p><br></p>

<p style="text-align: justify;">
  The Vehicle-Infrastructure platform is shown in <a href="#overview">Fig. 1</a>. Our onboard sensor suite consists of a multi-camera setup (event camera, industrial camera, 
  and infrared camera) equipped with three LiDARs, onboard IMU, two GNSS receivers, and GNSS-RTK/INS systems.
  The specific specifications of each sensor are presented in <a href="#Sensors specifications">Table. 1.</a> .
  An Intel NUC (i7-1260P, 32GB RAM) and an industrial computer (i7-10610U, 32GB RAM) are used to run sensor drivers, and record data into ROS bags on the Ubuntu system.
<br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/img/VI_sensor_kit.jpg" alt="Image description">
    <figcaption id="overview">Fig. 1. An overview of the Vehicle-Infrastructure sensor setup</figcaption>
  </figure>
</p>


<h4>Vehicle-Infrastructure sensor platform</h4>
<!-- <p style="text-align: justify;">
  An onboard Xsens-MTI-30 IMU is employed to collect the raw acceleration and angular velocity at 400 Hz.
  The accurate ground-truth of localization is furnished by a centimeter-level GNSS(GPS, GLONASS, and BeiDou)-RTK/INS(fiber-optic gyroscope) navigation system.
<br>
</p> -->

<p style="text-align: justify;">
The details of full sensors setup can be found below:</p>
<div style="text-align: center;">
  <table style="display: inline-block; border-collapse: collapse;" border="1" cellpadding="7">
    <tr><th>Platform</th><th>Sensor Type</th><th>Description</th></tr>

    <!-- Onboard Platform -->
    <tr>
      <td rowspan="7"><strong>Onboard Platform</strong></td>
      <td><strong>Hikvision MV-CS050-10GC PRO × 7</strong></td>
      <td>
        <ul>
          <li>Resolution: 2220 × 1740 pixels @ 10 fps</li>
          <li>H-FOV: 80.18°, V-FOV: 73.77°</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>Hesai XT-32</strong></td>
      <td>
        <ul>
          <li>H-FOV: 360°, V-FOV: +15° ~ -16°</li>
          <li>32 channels, 10 Hz</li>
          <li>Range: 125 m</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>Velodyne VLP-32E</strong></td>
      <td>
        <ul>
          <li>H-FOV: 360°, V-FOV: -30.67° ~ +10.67°</li>
          <li>32 channels, 10 Hz</li>
          <li>Range: 100 m</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>GPAL-Ares-R7861 Radar</strong></td>
      <td>
        <ul>
          <li>H-FOV: 150°, V-FOV: 30°</li>
          <li>Front-view radar</li>
          <li>Frequency: 13 Hz</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>Xsens MTi-30 IMU</strong></td>
      <td>
        <ul>
          <li>Sampling Rate: 400 Hz</li>
          <li>Accelerometer in-run bias instability: 15 µg</li>
          <li>Gyroscope in-run bias instability: 18°/h</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>U-Blox ZED-F9P</strong></td>
      <td>
        <ul>
          <li>Automotive Grade GNSS Receiver</li>
          <li>1 Hz, GPS Time</li>
        </ul>
      </td>
    </tr>

    <!-- <tr>
    <td><strong>U-Blox EVK-M8T</strong></td>
      <td>
        <ul>
          <li>Automotive Grade GNSS Receiver</li>
          <li>1 Hz, GPS Time</li>
        </ul>
      </td> -->
    <!-- </tr>  -->

    <tr>
      <td><strong>NovAtel SPAN-CPT</strong></td>
      <td>
        <ul>
          <li>Geodetic Grade GNSS/INS System</li>
          <li>1 Hz, GPS Time</li>
          <li>Position Accuracy: 5 cm</li>
        </ul>
      </td>
    </tr>

    <!-- Roadside Platform -->
    <tr>
      <td rowspan="3"><strong>Roadside Infrastructure</strong></td>
      <td><strong>Innovusion Jaguar LiDAR</strong></td>
      <td>
        <ul>
          <li>300 Lines</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>U-Blox ZED-F9P</strong></td>
      <td>
        <ul>
          <li>Automotive Grade GNSS Receiver</li>
          <li>1 Hz, GPS Time</li>
        </ul>
      </td>
    </tr>

    <tr>
      <td><strong>UWB Nooploop</strong></td>
      <td>
        <ul>
          <li>Model: P-B</li>
          <li>Frequency: 50 Hz</li>
        </ul>
      </td>
    </tr>
  </table>
</div>


<p style="text-align: justify;">
  We use an Ethernet topology for data transmission and time synchronization, as shown in <a href="#system_architecture">Fig. 2</a>. 
  All independent devices and the PTP server are synchronized using NMEA and PPS signals from a u-blox M8T GNSS receiver.
  PTP server synchronizes devices clocks by broadcasting PTPv2 messages. Ethernet cameras are triggered via GigE Vision with a timing accuracy of &lt; 0.005s. 
<br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/img/sys_architecture.png" alt="Image description">
    <figcaption id="system_architecture">Fig. 2. System architecture</figcaption>
  </figure>
</p>


<h4>Visual sensors</h4>
<p style="text-align: justify;">
  Seven Hikvision MV-CS050-10GC PRO cameras with 4mm lenses capture 2200×1740 RGB images at 10 Hz. 
  Two are forward-facing stereo cameras, while five form a 360° surround setup with 60° spacing and 20° overlap. The FOV coverage is shown in <a href="#cameras_fov_coverage">Fig. 3</a>
  Image synchronized trigger is achieved via the GigE Vision protocol.
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/img/cameras_fov_coverage.png" alt="Image description">
    <figcaption id="cameras_fov_coverage">Fig. 3. Cameras FOV Coverage</figcaption>
  </figure>
<br>
</p>
<h4>4D Radar</h4>
<p style="text-align: justify;">
  A front-mounted 4D radar GPAL Ares-R7861 measures object position, velocity, and distance in real time, producing 3D point clouds with velocity data. 
  It offers a 150° horizontal FOV and operates at 13 Hz. The point cloud view can be found in <a href="#radar_sample">Fig. 4</a>
  <br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/img/radar_sample.png" alt="Image description">
    <figcaption id="radar_sample">Fig. 4. Radar sample</figcaption>
  </figure>
</p>
<h4>Mechanical LiDAR</h4>
  <p style="text-align: justify;">
    Two mechanical LiDARs are used: a Velodyne HDL-32E on the vehicle roof for horizontal surroundings and a slanted Hesai XT-32 at the front for detailed urban architecture. 
    Two LiDAR point clouds are fused as <a href="#lidar_sample">Fig. 5</a>. Both operate at 10 Hz.
  <br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/img/lidar_sample.png" alt="Image description">
    <figcaption id="lidar_sample">Fig. 5. LiDAR sample</figcaption>
  </figure>
</p>

<h4>Roadside LiDAR</h4>
  <p style="text-align: justify;">
    Innovusion Jaguar LiDAR at 300 Lines cover the roundabout areas
  <br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/gif/roadside_lidar_sample.gif" alt="Image description">
    <figcaption id="lidar_sample">Fig. 6. Roadside LiDAR </figcaption>
  </figure>
</p>

<h4>Roadside UWB</h4>
  <p style="text-align: justify;">
    We deployed 4 UWB anchors with RSI, which ensure the communication between vehicle and RSU at the roundabout area.
  <br>
  <figure style="text-align: center;">
    <img style = "width: 90%" src="../assets/gif/roadside_uwb_sample.gif" alt="Image description">
    <figcaption id="roadside_UWB_sample">Fig. 7. Roadside UWB</figcaption>
  </figure>
</p>

  <p><br></p>

<!-- <ul>
  <li>2x <a href="https://www.prophesee.ai/buy-event-based-products/" target="_blank" rel="noopener noreferrer">Prophesee Gen3 CD</a> with <a href="https://lenses.kowa-usa.com/jcm-series/410-lm5jc1m.html" target="_blank" rel="noopener noreferrer">Kowa LM5JCM</a>
</li>
  <li>2x <a href="https://www.flir.com/products/grasshopper3-usb3/?model=GS3-U3-51S5C-C" target="_blank" rel="noopener noreferrer">FLIR Grasshopper3</a> with <a href="https://lenses.kowa-usa.com/jc-series/479-lm6jc.html" target="_blank" rel="noopener noreferrer">Kowa LM6JC</a>
</li>
  <li><a href="https://azure.microsoft.com/en-us/services/kinect-dk/" target="_blank" rel="noopener noreferrer">Azure Kinect</a></li>
  <li><a href="https://ouster.com/products/scanning-lidar/os0-sensor/" target="_blank" rel="noopener noreferrer">Ouster OS0-128</a></li>
  <li><a href="https://www.xsens.com/products/mti-10-series" target="_blank" rel="noopener noreferrer">XSens MTi-30 AHRS</a></li>
  <li><a href="https://optitrack.com/" target="_blank" rel="noopener noreferrer">OptiTrack Motion Capture (MoCap) System</a></li>
  <li><a href="https://www.faro.com/en/Products/Hardware/Focus-Laser-Scanners" target="_blank" rel="noopener noreferrer">FARO Focus Laser Scanner</a></li>
</ul> -->

          </article>

        </div>

    </div>

   <!-- Footer -->    
   <footer class="nofixed-bottom">
    <div class="container mt-0" style="width:100%;text-align:center;">
      © 2025 Tas Lab, The Hong Kong Polytechnic University. All rights reserved.
    </div>
  </footer> 

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/vector/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/vector/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/vector/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

